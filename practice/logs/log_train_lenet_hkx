I0826 16:52:08.344866 13242 caffe.cpp:211] Use CPU.
I0826 16:52:08.351084 13242 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/snapshot"
net: "examples/mnist/lenet_train_test_hkx.prototxt"
train_state {
  level: 0
  stage: ""
}
I0826 16:52:08.381968 13242 solver.cpp:87] Creating training net from net file: examples/mnist/lenet_train_test_hkx.prototxt
I0826 16:52:08.382947 13242 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0826 16:52:08.385026 13242 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy1
I0826 16:52:08.385468 13242 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip1_2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip1_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "ip1_2"
  top: "ip1_2"
}
layer {
  name: "ip2_1"
  type: "InnerProduct"
  bottom: "ip1_2"
  top: "ip2_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss1"
  type: "SoftmaxWithLoss"
  bottom: "ip2_1"
  bottom: "label"
  top: "loss"
}
I0826 16:52:08.386636 13242 layer_factory.hpp:77] Creating layer mnist
I0826 16:52:08.388893 13242 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0826 16:52:08.394038 13242 net.cpp:84] Creating Layer mnist
I0826 16:52:08.398216 13242 net.cpp:380] mnist -> data
I0826 16:52:08.398550 13242 net.cpp:380] mnist -> label
I0826 16:52:08.398689 13242 data_layer.cpp:45] output data size: 64,1,28,28
I0826 16:52:08.399392 13242 net.cpp:122] Setting up mnist
I0826 16:52:08.402912 13242 net.cpp:129] Top shape: 64 1 28 28 (50176)
I0826 16:52:08.402956 13242 net.cpp:129] Top shape: 64 (64)
I0826 16:52:08.402972 13242 net.cpp:137] Memory required for data: 200960
I0826 16:52:08.403002 13242 layer_factory.hpp:77] Creating layer conv1
I0826 16:52:08.403043 13242 net.cpp:84] Creating Layer conv1
I0826 16:52:08.403066 13242 net.cpp:406] conv1 <- data
I0826 16:52:08.403095 13242 net.cpp:380] conv1 -> conv1
I0826 16:52:08.405004 13242 net.cpp:122] Setting up conv1
I0826 16:52:08.406710 13242 net.cpp:129] Top shape: 64 20 24 24 (737280)
I0826 16:52:08.406759 13242 net.cpp:137] Memory required for data: 3150080
I0826 16:52:08.406822 13242 layer_factory.hpp:77] Creating layer pool1
I0826 16:52:08.406852 13242 net.cpp:84] Creating Layer pool1
I0826 16:52:08.406872 13242 net.cpp:406] pool1 <- conv1
I0826 16:52:08.406895 13242 net.cpp:380] pool1 -> pool1
I0826 16:52:08.406939 13242 net.cpp:122] Setting up pool1
I0826 16:52:08.406962 13242 net.cpp:129] Top shape: 64 20 12 12 (184320)
I0826 16:52:08.406980 13242 net.cpp:137] Memory required for data: 3887360
I0826 16:52:08.406997 13242 layer_factory.hpp:77] Creating layer conv2
I0826 16:52:08.407022 13242 net.cpp:84] Creating Layer conv2
I0826 16:52:08.407040 13242 net.cpp:406] conv2 <- pool1
I0826 16:52:08.407061 13242 net.cpp:380] conv2 -> conv2
I0826 16:52:08.413455 13242 net.cpp:122] Setting up conv2
I0826 16:52:08.419934 13242 net.cpp:129] Top shape: 64 50 8 8 (204800)
I0826 16:52:08.419958 13242 net.cpp:137] Memory required for data: 4706560
I0826 16:52:08.419991 13242 layer_factory.hpp:77] Creating layer pool2
I0826 16:52:08.420023 13242 net.cpp:84] Creating Layer pool2
I0826 16:52:08.420048 13242 net.cpp:406] pool2 <- conv2
I0826 16:52:08.420084 13242 net.cpp:380] pool2 -> pool2
I0826 16:52:08.420117 13242 net.cpp:122] Setting up pool2
I0826 16:52:08.420140 13242 net.cpp:129] Top shape: 64 50 4 4 (51200)
I0826 16:52:08.420213 13242 net.cpp:137] Memory required for data: 4911360
I0826 16:52:08.420234 13242 layer_factory.hpp:77] Creating layer ip1
I0826 16:52:08.420756 13242 net.cpp:84] Creating Layer ip1
I0826 16:52:08.420789 13242 net.cpp:406] ip1 <- pool2
I0826 16:52:08.420816 13242 net.cpp:380] ip1 -> ip1
I0826 16:52:08.457126 13242 net.cpp:122] Setting up ip1
I0826 16:52:08.459054 13242 net.cpp:129] Top shape: 64 500 (32000)
I0826 16:52:08.460319 13242 net.cpp:137] Memory required for data: 5039360
I0826 16:52:08.461463 13242 layer_factory.hpp:77] Creating layer relu1
I0826 16:52:08.462041 13242 net.cpp:84] Creating Layer relu1
I0826 16:52:08.462081 13242 net.cpp:406] relu1 <- ip1
I0826 16:52:08.462110 13242 net.cpp:367] relu1 -> ip1 (in-place)
I0826 16:52:08.462141 13242 net.cpp:122] Setting up relu1
I0826 16:52:08.463065 13242 net.cpp:129] Top shape: 64 500 (32000)
I0826 16:52:08.463109 13242 net.cpp:137] Memory required for data: 5167360
I0826 16:52:08.463129 13242 layer_factory.hpp:77] Creating layer ip1_2
I0826 16:52:08.463151 13242 net.cpp:84] Creating Layer ip1_2
I0826 16:52:08.463171 13242 net.cpp:406] ip1_2 <- ip1
I0826 16:52:08.463198 13242 net.cpp:380] ip1_2 -> ip1_2
I0826 16:52:08.472401 13242 net.cpp:122] Setting up ip1_2
I0826 16:52:08.482640 13242 net.cpp:129] Top shape: 64 50 (3200)
I0826 16:52:08.482683 13242 net.cpp:137] Memory required for data: 5180160
I0826 16:52:08.482719 13242 layer_factory.hpp:77] Creating layer relu1_2
I0826 16:52:08.482751 13242 net.cpp:84] Creating Layer relu1_2
I0826 16:52:08.482774 13242 net.cpp:406] relu1_2 <- ip1_2
I0826 16:52:08.482800 13242 net.cpp:367] relu1_2 -> ip1_2 (in-place)
I0826 16:52:08.482898 13242 net.cpp:122] Setting up relu1_2
I0826 16:52:08.482924 13242 net.cpp:129] Top shape: 64 50 (3200)
I0826 16:52:08.482944 13242 net.cpp:137] Memory required for data: 5192960
I0826 16:52:08.482961 13242 layer_factory.hpp:77] Creating layer ip2_1
I0826 16:52:08.482982 13242 net.cpp:84] Creating Layer ip2_1
I0826 16:52:08.482997 13242 net.cpp:406] ip2_1 <- ip1_2
I0826 16:52:08.483013 13242 net.cpp:380] ip2_1 -> ip2_1
I0826 16:52:08.483057 13242 net.cpp:122] Setting up ip2_1
I0826 16:52:08.483080 13242 net.cpp:129] Top shape: 64 10 (640)
I0826 16:52:08.483096 13242 net.cpp:137] Memory required for data: 5195520
I0826 16:52:08.483122 13242 layer_factory.hpp:77] Creating layer loss1
I0826 16:52:08.483144 13242 net.cpp:84] Creating Layer loss1
I0826 16:52:08.485950 13242 net.cpp:406] loss1 <- ip2_1
I0826 16:52:08.486001 13242 net.cpp:406] loss1 <- label
I0826 16:52:08.486034 13242 net.cpp:380] loss1 -> loss
I0826 16:52:08.486085 13242 layer_factory.hpp:77] Creating layer loss1
I0826 16:52:08.486138 13242 net.cpp:122] Setting up loss1
I0826 16:52:08.486163 13242 net.cpp:129] Top shape: (1)
I0826 16:52:08.486181 13242 net.cpp:132]     with loss weight 1
I0826 16:52:08.486217 13242 net.cpp:137] Memory required for data: 5195524
I0826 16:52:08.486237 13242 net.cpp:198] loss1 needs backward computation.
I0826 16:52:08.486260 13242 net.cpp:198] ip2_1 needs backward computation.
I0826 16:52:08.486279 13242 net.cpp:198] relu1_2 needs backward computation.
I0826 16:52:08.486299 13242 net.cpp:198] ip1_2 needs backward computation.
I0826 16:52:08.486317 13242 net.cpp:198] relu1 needs backward computation.
I0826 16:52:08.486382 13242 net.cpp:198] ip1 needs backward computation.
I0826 16:52:08.486400 13242 net.cpp:198] pool2 needs backward computation.
I0826 16:52:08.486418 13242 net.cpp:198] conv2 needs backward computation.
I0826 16:52:08.486435 13242 net.cpp:198] pool1 needs backward computation.
I0826 16:52:08.486451 13242 net.cpp:198] conv1 needs backward computation.
I0826 16:52:08.486469 13242 net.cpp:200] mnist does not need backward computation.
I0826 16:52:08.486486 13242 net.cpp:242] This network produces output loss
I0826 16:52:08.486519 13242 net.cpp:255] Network initialization done.
I0826 16:52:08.487023 13242 solver.cpp:172] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test_hkx.prototxt
I0826 16:52:08.492004 13242 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0826 16:52:08.492200 13242 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip1_2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip1_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 50
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "ip1_2"
  top: "ip1_2"
}
layer {
  name: "ip2_1"
  type: "InnerProduct"
  bottom: "ip1_2"
  top: "ip2_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy1"
  type: "Accuracy"
  bottom: "ip2_1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss1"
  type: "SoftmaxWithLoss"
  bottom: "ip2_1"
  bottom: "label"
  top: "loss"
}
I0826 16:52:08.496124 13242 layer_factory.hpp:77] Creating layer mnist
I0826 16:52:08.496243 13242 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0826 16:52:08.496295 13242 net.cpp:84] Creating Layer mnist
I0826 16:52:08.496320 13242 net.cpp:380] mnist -> data
I0826 16:52:08.498081 13242 net.cpp:380] mnist -> label
I0826 16:52:08.498196 13242 data_layer.cpp:45] output data size: 100,1,28,28
I0826 16:52:08.499308 13242 net.cpp:122] Setting up mnist
I0826 16:52:08.503536 13242 net.cpp:129] Top shape: 100 1 28 28 (78400)
I0826 16:52:08.503577 13242 net.cpp:129] Top shape: 100 (100)
I0826 16:52:08.503594 13242 net.cpp:137] Memory required for data: 314000
I0826 16:52:08.503615 13242 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0826 16:52:08.503648 13242 net.cpp:84] Creating Layer label_mnist_1_split
I0826 16:52:08.503665 13242 net.cpp:406] label_mnist_1_split <- label
I0826 16:52:08.503686 13242 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0
I0826 16:52:08.503713 13242 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1
I0826 16:52:08.503742 13242 net.cpp:122] Setting up label_mnist_1_split
I0826 16:52:08.503763 13242 net.cpp:129] Top shape: 100 (100)
I0826 16:52:08.503782 13242 net.cpp:129] Top shape: 100 (100)
I0826 16:52:08.503798 13242 net.cpp:137] Memory required for data: 314800
I0826 16:52:08.503814 13242 layer_factory.hpp:77] Creating layer conv1
I0826 16:52:08.503844 13242 net.cpp:84] Creating Layer conv1
I0826 16:52:08.503861 13242 net.cpp:406] conv1 <- data
I0826 16:52:08.504925 13242 net.cpp:380] conv1 -> conv1
I0826 16:52:08.505064 13242 net.cpp:122] Setting up conv1
I0826 16:52:08.512244 13242 net.cpp:129] Top shape: 100 20 24 24 (1152000)
I0826 16:52:08.512307 13242 net.cpp:137] Memory required for data: 4922800
I0826 16:52:08.512344 13242 layer_factory.hpp:77] Creating layer pool1
I0826 16:52:08.512382 13242 net.cpp:84] Creating Layer pool1
I0826 16:52:08.512473 13242 net.cpp:406] pool1 <- conv1
I0826 16:52:08.512507 13242 net.cpp:380] pool1 -> pool1
I0826 16:52:08.512626 13242 net.cpp:122] Setting up pool1
I0826 16:52:08.513766 13242 net.cpp:129] Top shape: 100 20 12 12 (288000)
I0826 16:52:08.513805 13242 net.cpp:137] Memory required for data: 6074800
I0826 16:52:08.513826 13242 layer_factory.hpp:77] Creating layer conv2
I0826 16:52:08.513880 13242 net.cpp:84] Creating Layer conv2
I0826 16:52:08.514019 13242 net.cpp:406] conv2 <- pool1
I0826 16:52:08.514055 13242 net.cpp:380] conv2 -> conv2
I0826 16:52:08.514355 13242 net.cpp:122] Setting up conv2
I0826 16:52:08.514395 13242 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0826 16:52:08.514469 13242 net.cpp:137] Memory required for data: 7354800
I0826 16:52:08.514503 13242 layer_factory.hpp:77] Creating layer pool2
I0826 16:52:08.514528 13242 net.cpp:84] Creating Layer pool2
I0826 16:52:08.514891 13242 net.cpp:406] pool2 <- conv2
I0826 16:52:08.537014 13242 net.cpp:380] pool2 -> pool2
I0826 16:52:08.537354 13242 net.cpp:122] Setting up pool2
I0826 16:52:08.537390 13242 net.cpp:129] Top shape: 100 50 4 4 (80000)
I0826 16:52:08.537410 13242 net.cpp:137] Memory required for data: 7674800
I0826 16:52:08.537428 13242 layer_factory.hpp:77] Creating layer ip1
I0826 16:52:08.537508 13242 net.cpp:84] Creating Layer ip1
I0826 16:52:08.537536 13242 net.cpp:406] ip1 <- pool2
I0826 16:52:08.537567 13242 net.cpp:380] ip1 -> ip1
I0826 16:52:08.568758 13242 net.cpp:122] Setting up ip1
I0826 16:52:08.573139 13242 net.cpp:129] Top shape: 100 500 (50000)
I0826 16:52:08.573750 13242 net.cpp:137] Memory required for data: 7874800
I0826 16:52:08.573802 13242 layer_factory.hpp:77] Creating layer relu1
I0826 16:52:08.573839 13242 net.cpp:84] Creating Layer relu1
I0826 16:52:08.573863 13242 net.cpp:406] relu1 <- ip1
I0826 16:52:08.573885 13242 net.cpp:367] relu1 -> ip1 (in-place)
I0826 16:52:08.573911 13242 net.cpp:122] Setting up relu1
I0826 16:52:08.573933 13242 net.cpp:129] Top shape: 100 500 (50000)
I0826 16:52:08.573951 13242 net.cpp:137] Memory required for data: 8074800
I0826 16:52:08.573967 13242 layer_factory.hpp:77] Creating layer ip1_2
I0826 16:52:08.573997 13242 net.cpp:84] Creating Layer ip1_2
I0826 16:52:08.574025 13242 net.cpp:406] ip1_2 <- ip1
I0826 16:52:08.576913 13242 net.cpp:380] ip1_2 -> ip1_2
I0826 16:52:08.578408 13242 net.cpp:122] Setting up ip1_2
I0826 16:52:08.580546 13242 net.cpp:129] Top shape: 100 50 (5000)
I0826 16:52:08.580869 13242 net.cpp:137] Memory required for data: 8094800
I0826 16:52:08.581004 13242 layer_factory.hpp:77] Creating layer relu1_2
I0826 16:52:08.581961 13242 net.cpp:84] Creating Layer relu1_2
I0826 16:52:08.582499 13242 net.cpp:406] relu1_2 <- ip1_2
I0826 16:52:08.582553 13242 net.cpp:367] relu1_2 -> ip1_2 (in-place)
I0826 16:52:08.582620 13242 net.cpp:122] Setting up relu1_2
I0826 16:52:08.582649 13242 net.cpp:129] Top shape: 100 50 (5000)
I0826 16:52:08.582665 13242 net.cpp:137] Memory required for data: 8114800
I0826 16:52:08.582680 13242 layer_factory.hpp:77] Creating layer ip2_1
I0826 16:52:08.582703 13242 net.cpp:84] Creating Layer ip2_1
I0826 16:52:08.582721 13242 net.cpp:406] ip2_1 <- ip1_2
I0826 16:52:08.582743 13242 net.cpp:380] ip2_1 -> ip2_1
I0826 16:52:08.582788 13242 net.cpp:122] Setting up ip2_1
I0826 16:52:08.582808 13242 net.cpp:129] Top shape: 100 10 (1000)
I0826 16:52:08.582823 13242 net.cpp:137] Memory required for data: 8118800
I0826 16:52:08.582850 13242 layer_factory.hpp:77] Creating layer ip2_1_ip2_1_0_split
I0826 16:52:08.582922 13242 net.cpp:84] Creating Layer ip2_1_ip2_1_0_split
I0826 16:52:08.582976 13242 net.cpp:406] ip2_1_ip2_1_0_split <- ip2_1
I0826 16:52:08.586295 13242 net.cpp:380] ip2_1_ip2_1_0_split -> ip2_1_ip2_1_0_split_0
I0826 16:52:08.596312 13242 net.cpp:380] ip2_1_ip2_1_0_split -> ip2_1_ip2_1_0_split_1
I0826 16:52:08.596391 13242 net.cpp:122] Setting up ip2_1_ip2_1_0_split
I0826 16:52:08.596418 13242 net.cpp:129] Top shape: 100 10 (1000)
I0826 16:52:08.596437 13242 net.cpp:129] Top shape: 100 10 (1000)
I0826 16:52:08.596454 13242 net.cpp:137] Memory required for data: 8126800
I0826 16:52:08.596472 13242 layer_factory.hpp:77] Creating layer accuracy1
I0826 16:52:08.596493 13242 net.cpp:84] Creating Layer accuracy1
I0826 16:52:08.596510 13242 net.cpp:406] accuracy1 <- ip2_1_ip2_1_0_split_0
I0826 16:52:08.596534 13242 net.cpp:406] accuracy1 <- label_mnist_1_split_0
I0826 16:52:08.596581 13242 net.cpp:380] accuracy1 -> accuracy
I0826 16:52:08.596609 13242 net.cpp:122] Setting up accuracy1
I0826 16:52:08.614054 13242 net.cpp:129] Top shape: (1)
I0826 16:52:08.614075 13242 net.cpp:137] Memory required for data: 8126804
I0826 16:52:08.614084 13242 layer_factory.hpp:77] Creating layer loss1
I0826 16:52:08.614105 13242 net.cpp:84] Creating Layer loss1
I0826 16:52:08.614112 13242 net.cpp:406] loss1 <- ip2_1_ip2_1_0_split_1
I0826 16:52:08.614121 13242 net.cpp:406] loss1 <- label_mnist_1_split_1
I0826 16:52:08.614130 13242 net.cpp:380] loss1 -> loss
I0826 16:52:08.614143 13242 layer_factory.hpp:77] Creating layer loss1
I0826 16:52:08.624549 13242 net.cpp:122] Setting up loss1
I0826 16:52:08.624580 13242 net.cpp:129] Top shape: (1)
I0826 16:52:08.624585 13242 net.cpp:132]     with loss weight 1
I0826 16:52:08.624599 13242 net.cpp:137] Memory required for data: 8126808
I0826 16:52:08.624606 13242 net.cpp:198] loss1 needs backward computation.
I0826 16:52:08.624614 13242 net.cpp:200] accuracy1 does not need backward computation.
I0826 16:52:08.624619 13242 net.cpp:198] ip2_1_ip2_1_0_split needs backward computation.
I0826 16:52:08.624622 13242 net.cpp:198] ip2_1 needs backward computation.
I0826 16:52:08.624626 13242 net.cpp:198] relu1_2 needs backward computation.
I0826 16:52:08.624630 13242 net.cpp:198] ip1_2 needs backward computation.
I0826 16:52:08.624635 13242 net.cpp:198] relu1 needs backward computation.
I0826 16:52:08.624639 13242 net.cpp:198] ip1 needs backward computation.
I0826 16:52:08.624644 13242 net.cpp:198] pool2 needs backward computation.
I0826 16:52:08.624647 13242 net.cpp:198] conv2 needs backward computation.
I0826 16:52:08.624651 13242 net.cpp:198] pool1 needs backward computation.
I0826 16:52:08.624655 13242 net.cpp:198] conv1 needs backward computation.
I0826 16:52:08.624660 13242 net.cpp:200] label_mnist_1_split does not need backward computation.
I0826 16:52:08.624680 13242 net.cpp:200] mnist does not need backward computation.
I0826 16:52:08.624685 13242 net.cpp:242] This network produces output accuracy
I0826 16:52:08.624805 13242 net.cpp:242] This network produces output loss
I0826 16:52:08.624836 13242 net.cpp:255] Network initialization done.
I0826 16:52:08.624909 13242 solver.cpp:56] Solver scaffolding done.
I0826 16:52:08.624958 13242 caffe.cpp:155] Finetuning from ./examples/mnist/lenet_iter_10000.caffemodel
I0826 16:52:08.640579 13242 net.cpp:744] Ignoring source layer ip2
I0826 16:52:08.640655 13242 net.cpp:744] Ignoring source layer loss
I0826 16:52:08.662190 13242 net.cpp:744] Ignoring source layer ip2
I0826 16:52:08.663866 13242 net.cpp:744] Ignoring source layer loss
I0826 16:52:08.664597 13242 caffe.cpp:248] Starting Optimization
I0826 16:52:08.664630 13242 solver.cpp:272] Solving LeNet
I0826 16:52:08.664649 13242 solver.cpp:273] Learning Rate Policy: inv
I0826 16:52:08.665292 13242 solver.cpp:330] Iteration 0, Testing net (#0)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   I0826 16:52:25.180321 12994 solver.cpp:330] Iteration 5500, Testing net (#0)
I0826 16:52:55.480561 12997 data_layer.cpp:73] Restarting data prefetching from start.
I0826 16:52:57.793488 12994 solver.cpp:397]     Test net output #0: accuracy = 0.9894
I0826 16:52:57.799208 12994 solver.cpp:397]     Test net output #1: loss = 0.032182 (* 1 = 0.032182 loss)
I0826 16:52:58.327854 12994 solver.cpp:218] Iteration 5500 (1.14961 iter/s, 86.986s/100 iters), loss = 0.00239015
I0826 16:52:58.330996 12994 solver.cpp:237]     Train net output #0: loss = 0.00239012 (* 1 = 0.00239012 loss)
I0826 16:52:58.331158 12994 sgd_solver.cpp:105] Iteration 5500, lr = 0.00719865
I0826 16:53:53.823112 12994 solver.cpp:218] Iteration 5600 (1.80206 iter/s, 55.492s/100 iters), loss = 0.000398445
I0826 16:53:53.823473 12994 solver.cpp:237]     Train net output #0: loss = 0.000398417 (* 1 = 0.000398417 loss)
I0826 16:53:53.823604 12994 sgd_solver.cpp:105] Iteration 5600, lr = 0.00716402
I0826 16:54:04.229328 12996 data_layer.cpp:73] Restarting data prefetching from start.
I0826 16:54:41.260846 12994 solver.cpp:218] Iteration 5700 (2.10806 iter/s, 47.437s/100 iters), loss = 0.00159722
I0826 16:54:41.264662 12994 solver.cpp:237]     Train net output #0: loss = 0.00159718 (* 1 = 0.00159718 loss)
I0826 16:54:41.264783 12994 sgd_solver.cpp:105] Iteration 5700, lr = 0.00712977
I0826 16:55:34.415917 12994 solver.cpp:218] Iteration 5800 (1.88143 iter/s, 53.151s/100 iters), loss = 0.005865
I0826 16:55:34.416188 12994 solver.cpp:237]     Train net output #0: loss = 0.00586497 (* 1 = 0.00586497 loss)
I0826 16:55:34.416296 12994 sgd_solver.cpp:105] Iteration 5800, lr = 0.0070959
I0826 16:56:16.994551 12994 solver.cpp:218] Iteration 5900 (2.34863 iter/s, 42.578s/100 iters), loss = 0.0028382
I0826 16:56:16.994912 12994 solver.cpp:237]     Train net output #0: loss = 0.00283816 (* 1 = 0.00283816 loss)
I0826 16:56:16.995012 12994 sgd_solver.cpp:105] Iteration 5900, lr = 0.0070624
I0826 16:57:01.241868 12994 solver.cpp:330] Iteration 6000, Testing net (#0)
I0826 16:57:26.660575 12997 data_layer.cpp:73] Restarting data prefetching from start.
I0826 16:57:28.060467 12994 solver.cpp:397]     Test net output #0: accuracy = 0.9919
I0826 16:57:28.060853 12994 solver.cpp:397]     Test net output #1: loss = 0.0264322 (* 1 = 0.0264322 loss)
I0826 16:57:28.562465 12994 solver.cpp:218] Iteration 6000 (1.39729 iter/s, 71.567s/100 iters), loss = 0.00285285
I0826 16:57:28.565721 12994 solver.cpp:237]     Train net output #0: loss = 0.00285281 (* 1 = 0.00285281 loss)
I0826 16:57:28.566128 12994 sgd_solver.cpp:105] Iteration 6000, lr = 0.00702927
I0826 16:58:26.017709 12994 solver.cpp:218] Iteration 6100 (1.74061 iter/s, 57.451s/100 iters), loss = 0.00068507
I0826 16:58:26.020754 12994 solver.cpp:237]     Train net output #0: loss = 0.000685038 (* 1 = 0.000685038 loss)
I0826 16:58:26.020890 12994 sgd_solver.cpp:105] Iteration 6100, lr = 0.0069965
I0826 16:59:19.236508 12994 solver.cpp:218] Iteration 6200 (1.87917 iter/s, 53.215s/100 iters), loss = 0.00193058
I0826 16:59:19.236783 12994 solver.cpp:237]     Train net output #0: loss = 0.00193055 (* 1 = 0.00193055 loss)
I0826 16:59:19.237493 12994 sgd_solver.cpp:105] Iteration 6200, lr = 0.00696408
I0826 17:00:27.519791 12994 solver.cpp:218] Iteration 6300 (1.46451 iter/s, 68.282s/100 iters), loss = 0.00238522
I0826 17:00:27.520098 12994 solver.cpp:237]     Train net output #0: loss = 0.00238518 (* 1 = 0.00238518 loss)
I0826 17:00:27.520200 12994 sgd_solver.cpp:105] Iteration 6300, lr = 0.00693201
I0826 17:01:36.919337 12994 solver.cpp:218] Iteration 6400 (1.44094 iter/s, 69.399s/100 iters), loss = 0.00245578
I0826 17:01:36.919626 12994 solver.cpp:237]     Train net output #0: loss = 0.00245574 (* 1 = 0.00245574 loss)
I0826 17:01:36.919729 12994 sgd_solver.cpp:105] Iteration 6400, lr = 0.00690029
I0826 17:02:39.464216 12994 solver.cpp:330] Iteration 6500, Testing net (#0)
I0826 17:03:14.057896 12997 data_layer.cpp:73] Restarting data prefetching from start.
I0826 17:03:15.591819 12994 solver.cpp:397]     Test net output #0: accuracy = 0.991
I0826 17:03:15.592067 12994 solver.cpp:397]     Test net output #1: loss = 0.0290863 (* 1 = 0.0290863 loss)
I0826 17:03:16.224258 12994 solver.cpp:218] Iteration 6500 (1.00701 iter/s, 99.304s/100 iters), loss = 0.00430732
I0826 17:03:16.224755 12994 solver.cpp:237]     Train net output #0: loss = 0.00430728 (* 1 = 0.00430728 loss)
I0826 17:03:16.224874 12994 sgd_solver.cpp:105] Iteration 6500, lr = 0.0068689
I0826 17:03:57.610518 12996 data_layer.cpp:73] Restarting data prefetching from start.
I0826 17:04:27.239773 12994 solver.cpp:218] Iteration 6600 (1.40817 iter/s, 71.014s/100 iters), loss = 0.0149541
I0826 17:04:27.246456 12994 solver.cpp:237]     Train net output #0: loss = 0.0149541 (* 1 = 0.0149541 loss)
I0826 17:04:27.246587 12994 sgd_solver.cpp:105] Iteration 6600, lr = 0.00683784
I0826 17:05:09.885718 12994 solver.cpp:218] Iteration 6700 (2.34527 iter/s, 42.639s/100 iters), loss = 0.00288167
I0826 17:05:09.886158 12994 solver.cpp:237]     Train net output #0: loss = 0.00288163 (* 1 = 0.00288163 loss)
I0826 17:05:09.886276 12994 sgd_solver.cpp:105] Iteration 6700, lr = 0.00680711
I0826 17:05:42.969283 12994 solver.cpp:218] Iteration 6800 (3.0227 iter/s, 33.083s/100 iters), loss = 0.00103048
I0826 17:05:42.969542 12994 solver.cpp:237]     Train net output #0: loss = 0.00103044 (* 1 = 0.00103044 loss)
I0826 17:05:42.969635 12994 sgd_solver.cpp:105] Iteration 6800, lr = 0.0067767
I0826 17:06:17.604329 12994 solver.cpp:218] Iteration 6900 (2.88734 iter/s, 34.634s/100 iters), loss = 0.00176415
I0826 17:06:17.604714 12994 solver.cpp:237]     Train net output #0: loss = 0.0017641 (* 1 = 0.0017641 loss)
I0826 17:06:17.604830 12994 sgd_solver.cpp:105] Iteration 6900, lr = 0.0067466
I0826 17:06:51.484731 12994 solver.cpp:330] Iteration 7000, Testing net (#0)
I0826 17:07:13.273883 12997 data_layer.cpp:73] Restarting data prefetching from start.
I0826 17:07:14.993300 12994 solver.cpp:397]     Test net output #0: accuracy = 0.9911
I0826 17:07:14.993561 12994 solver.cpp:397]     Test net output #1: loss = 0.0270343 (* 1 = 0.0270343 loss)
I0826 17:07:15.887297 12994 solver.cpp:218] Iteration 7000 (1.7158 iter/s, 58.282s/100 iters), loss = 0.00165687
I0826 17:07:15.890954 12994 solver.cpp:237]     Train net output #0: loss = 0.00165683 (* 1 = 0.00165683 loss)
I0826 17:07:15.891083 12994 sgd_solver.cpp:105] Iteration 7000, lr = 0.00671681
I0826 17:08:21.634848 12994 solver.cpp:218] Iteration 7100 (1.52107 iter/s, 65.743s/100 iters), loss = 0.007973
I0826 17:08:21.661947 12994 solver.cpp:237]     Train net output #0: loss = 0.00797295 (* 1 = 0.00797295 loss)
I0826 17:08:21.661983 12994 sgd_solver.cpp:105] Iteration 7100, lr = 0.00668733
I0826 17:09:24.694624 12994 solver.cpp:218] Iteration 7200 (1.5865 iter/s, 63.032s/100 iters), loss = 0.00262533
I0826 17:09:24.694977 12994 solver.cpp:237]     Train net output #0: loss = 0.00262529 (* 1 = 0.00262529 loss)
I0826 17:09:24.695086 12994 sgd_solver.cpp:105] Iteration 7200, lr = 0.00665815
I0826 17:09:59.238137 12994 solver.cpp:218] Iteration 7300 (2.89494 iter/s, 34.543s/100 iters), loss = 0.00753516
I0826 17:09:59.238502 12994 solver.cpp:237]     Train net output #0: loss = 0.00753511 (* 1 = 0.00753511 loss)
I0826 17:09:59.238621 12994 sgd_solver.cpp:105] Iteration 7300, lr = 0.00662927
I0826 17:10:32.753684 12994 solver.cpp:218] Iteration 7400 (2.98374 iter/s, 33.515s/100 iters), loss = 0.00360397
I0826 17:10:32.754192 12994 solver.cpp:237]     Train net output #0: loss = 0.00360393 (* 1 = 0.00360393 loss)
I0826 17:10:32.754370 12994 sgd_solver.cpp:105] Iteration 7400, lr = 0.00660067
I0826 17:11:06.996816 12996 data_layer.cpp:73] Restarting data prefetching from start.
I0826 17:11:08.265792 12994 solver.cpp:330] Iteration 7500, Testing net (#0)
I0826 17:11:27.814111 12997 data_layer.cpp:73] Restarting data prefetching from start.
I0826 17:11:28.614392 12994 solver.cpp:397]     Test net output #0: accuracy = 0.9913
I0826 17:11:28.614626 12994 solver.cpp:397]     Test net output #1: loss = 0.0298296 (* 1 = 0.0298296 loss)
I0826 17:11:28.975534 12994 solver.cpp:218] Iteration 7500 (1.77869 iter/s, 56.221s/100 iters), loss = 0.000722616
I0826 17:11:28.975889 12994 solver.cpp:237]     Train net output #0: loss = 0.00072257 (* 1 = 0.00072257 loss)
I0826 17:11:28.976027 12994 sgd_solver.cpp:105] Iteration 7500, lr = 0.00657236
I0826 17:12:02.760773 12994 solver.cpp:218] Iteration 7600 (2.95998 iter/s, 33.784s/100 iters), loss = 0.0030285
I0826 17:12:02.761246 12994 solver.cpp:237]     Train net output #0: loss = 0.00302845 (* 1 = 0.00302845 loss)
I0826 17:12:02.762013 12994 sgd_solver.cpp:105] Iteration 7600, lr = 0.00654433
I0826 17:12:36.725145 12994 solver.cpp:218] Iteration 7700 (2.94438 iter/s, 33.963s/100 iters), loss = 0.00772336
I0826 17:12:36.727614 12994 solver.cpp:237]     Train net output #0: loss = 0.00772332 (* 1 = 0.00772332 loss)
I0826 17:12:36.728817 12994 sgd_solver.cpp:105] Iteration 7700, lr = 0.00651658
I0826 17:13:09.560660 12994 solver.cpp:218] Iteration 7800 (3.04572 iter/s, 32.833s/100 iters), loss = 0.00215778
I0826 17:13:09.562609 12994 solver.cpp:237]     Train net output #0: loss = 0.00215774 (* 1 = 0.00215774 loss)
I0826 17:13:09.564566 12994 sgd_solver.cpp:105] Iteration 7800, lr = 0.00648911
I0826 17:13:42.777640 12994 solver.cpp:218] Iteration 7900 (3.01069 iter/s, 33.215s/100 iters), loss = 0.000814885
I0826 17:13:42.779549 12994 solver.cpp:237]     Train net output #0: loss = 0.000814839 (* 1 = 0.000814839 loss)
I0826 17:13:42.782027 12994 sgd_solver.cpp:105] Iteration 7900, lr = 0.0064619
I0826 17:14:14.940012 12994 solver.cpp:330] Iteration 8000, Testing net (#0)
I0826 17:14:33.294694 12997 data_layer.cpp:73] Restarting data prefetching from start.
I0826 17:14:34.177358 12994 solver.cpp:397]     Test net output #0: accuracy = 0.9914
I0826 17:14:34.177901 12994 solver.cpp:397]     Test net output #1: loss = 0.0269292 (* 1 = 0.0269292 loss)
I0826 17:14:34.566166 12994 solver.cpp:218] Iteration 8000 (1.93102 iter/s, 51.786s/100 iters), loss = 0.00432488
I0826 17:14:34.567997 12994 solver.cpp:237]     Train net output #0: loss = 0.00432483 (* 1 = 0.00432483 loss)
I0826 17:14:34.569926 12994 sgd_solver.cpp:105] Iteration 8000, lr = 0.00643496
I0826 17:15:07.388196 12994 solver.cpp:218] Iteration 8100 (3.04692 iter/s, 32.82s/100 iters), loss = 0.00825595
I0826 17:15:07.392724 12994 solver.cpp:237]     Train net output #0: loss = 0.0082559 (* 1 = 0.0082559 loss)
I0826 17:15:07.392786 12994 sgd_solver.cpp:105] Iteration 8100, lr = 0.00640827
I0826 17:15:39.338629 12994 solver.cpp:218] Iteration 8200 (3.13038 iter/s, 31.945s/100 iters), loss = 0.00290901
I0826 17:15:39.341089 12994 solver.cpp:237]     Train net output #0: loss = 0.00290896 (* 1 = 0.00290896 loss)
I0826 17:15:39.343394 12994 sgd_solver.cpp:105] Iteration 8200, lr = 0.00638185
I0826 17:16:12.956207 12994 solver.cpp:218] Iteration 8300 (2.97486 iter/s, 33.615s/100 iters), loss = 0.0104315
I0826 17:16:12.958446 12994 solver.cpp:237]     Train net output #0: loss = 0.0104315 (* 1 = 0.0104315 loss)
I0826 17:16:12.960247 12994 sgd_solver.cpp:105] Iteration 8300, lr = 0.00635567
I0826 17:16:46.400136 12994 solver.cpp:218] Iteration 8400 (2.99034 iter/s, 33.441s/100 iters), loss = 0.00361262
I0826 17:16:46.403635 12994 solver.cpp:237]     Train net output #0: loss = 0.00361257 (* 1 = 0.00361257 loss)
I0826 17:16:46.403723 12994 sgd_solver.cpp:105] Iteration 8400, lr = 0.00632975
I0826 17:16:57.449193 12996 data_layer.cpp:73] Restarting data prefetching from start.
I0826 17:17:21.390346 12994 solver.cpp:330] Iteration 8500, Testing net (#0)
I0826 17:17:39.968075 12997 data_layer.cpp:73] Restarting data prefetching from start.
I0826 17:17:40.831867 12994 solver.cpp:397]     Test net output #0: accuracy = 0.9914
I0826 17:17:40.836447 12994 solver.cpp:397]     Test net output #1: loss = 0.0271307 (* 1 = 0.0271307 loss)
I0826 17:17:41.232878 12994 solver.cpp:218] Iteration 8500 (1.82385 iter/s, 54.829s/100 iters), loss = 0.00412249
I0826 17:17:41.235499 12994 solver.cpp:237]     Train net output #0: loss = 0.00412245 (* 1 = 0.00412245 loss)
I0826 17:17:41.237228 12994 sgd_solver.cpp:105] Iteration 8500, lr = 0.00630407
I0826 17:18:16.737761 12994 solver.cpp:218] Iteration 8600 (2.81674 iter/s, 35.502s/100 iters), loss = 0.000451607
I0826 17:18:16.740058 12994 solver.cpp:237]     Train net output #0: loss = 0.000451561 (* 1 = 0.000451561 loss)
I0826 17:18:16.742308 12994 sgd_solver.cpp:105] Iteration 8600, lr = 0.00627864
I0826 17:18:49.853902 12994 solver.cpp:218] Iteration 8700 (3.01996 iter/s, 33.113s/100 iters), loss = 0.00112151
I0826 17:18:49.856137 12994 solver.cpp:237]     Train net output #0: loss = 0.00112147 (* 1 = 0.00112147 loss)
I0826 17:18:49.858001 12994 sgd_solver.cpp:105] Iteration 8700, lr = 0.00625344
I0826 17:19:22.117332 12994 solver.cpp:218] Iteration 8800 (3.09972 iter/s, 32.261s/100 iters), loss = 0.00120786
I0826 17:19:22.119587 12994 solver.cpp:237]     Train net output #0: loss = 0.00120782 (* 1 = 0.00120782 loss)
I0826 17:19:22.121531 12994 sgd_solver.cpp:105] Iteration 8800, lr = 0.00622847
I0826 17:20:16.353368 12994 solver.cpp:218] Iteration 8900 (1.8439 iter/s, 54.233s/100 iters), loss = 0.000258065
I0826 17:20:16.361543 12994 solver.cpp:237]     Train net output #0: loss = 0.000258015 (* 1 = 0.000258015 loss)
I0826 17:20:16.362421 12994 sgd_solver.cpp:105] Iteration 8900, lr = 0.00620374
I0826 17:21:12.352792 12994 solver.cpp:330] Iteration 9000, Testing net (#0)
I0826 17:21:29.924929 12997 data_layer.cpp:73] Restarting data prefetching from start.
I0826 17:21:30.738517 12994 solver.cpp:397]     Test net output #0: accuracy = 0.9913
I0826 17:21:30.740123 12994 solver.cpp:397]     Test net output #1: loss = 0.02596 (* 1 = 0.02596 loss)
I0826 17:21:31.142573 12994 solver.cpp:218] Iteration 9000 (1.33724 iter/s, 74.781s/100 iters), loss = 0.00634198
I0826 17:21:31.144364 12994 solver.cpp:237]     Train net output #0: loss = 0.00634193 (* 1 = 0.00634193 loss)
I0826 17:21:31.146214 12994 sgd_solver.cpp:105] Iteration 9000, lr = 0.00617924
I0826 17:22:03.037983 12994 solver.cpp:218] Iteration 9100 (3.13548 iter/s, 31.893s/100 iters), loss = 0.00342871
I0826 17:22:03.039896 12994 solver.cpp:237]     Train net output #0: loss = 0.00342866 (* 1 = 0.00342866 loss)
I0826 17:22:03.041821 12994 sgd_solver.cpp:105] Iteration 9100, lr = 0.00615496
I0826 17:22:34.848337 12994 solver.cpp:218] Iteration 9200 (3.14386 iter/s, 31.808s/100 iters), loss = 0.00248773
I0826 17:22:34.850612 12994 solver.cpp:237]     Train net output #0: loss = 0.00248768 (* 1 = 0.00248768 loss)
I0826 17:22:34.852615 12994 sgd_solver.cpp:105] Iteration 9200, lr = 0.0061309
I0826 17:23:10.676836 12994 solver.cpp:218] Iteration 9300 (2.79127 iter/s, 35.826s/100 iters), loss = 0.0039529
I0826 17:23:10.678997 12994 solver.cpp:237]     Train net output #0: loss = 0.00395285 (* 1 = 0.00395285 loss)
I0826 17:23:10.680919 12994 sgd_solver.cpp:105] Iteration 9300, lr = 0.00610706
I0826 17:23:33.792093 12996 data_layer.cpp:73] Restarting data prefetching from start.
I0826 17:23:43.781117 12994 solver.cpp:218] Iteration 9400 (3.02097 iter/s, 33.102s/100 iters), loss = 0.00554686
I0826 17:23:43.783428 12994 solver.cpp:237]     Train net output #0: loss = 0.0055468 (* 1 = 0.0055468 loss)
I0826 17:23:43.785189 12994 sgd_solver.cpp:105] Iteration 9400, lr = 0.00608343
I0826 17:24:16.784487 12994 solver.cpp:330] Iteration 9500, Testing net (#0)
I0826 17:24:35.438812 12997 data_layer.cpp:73] Restarting data prefetching from start.
I0826 17:24:36.252261 12994 solver.cpp:397]     Test net output #0: accuracy = 0.9901
I0826 17:24:36.254432 12994 solver.cpp:397]     Test net output #1: loss = 0.0307859 (* 1 = 0.0307859 loss)
I0826 17:24:36.655740 12994 solver.cpp:218] Iteration 9500 (1.89136 iter/s, 52.872s/100 iters), loss = 0.00197486
I0826 17:24:36.657874 12994 solver.cpp:237]     Train net output #0: loss = 0.00197481 (* 1 = 0.00197481 loss)
I0826 17:24:36.659778 12994 sgd_solver.cpp:105] Iteration 9500, lr = 0.00606002
I0826 17:25:10.886363 12994 solver.cpp:218] Iteration 9600 (2.92158 iter/s, 34.228s/100 iters), loss = 0.00234186
I0826 17:25:10.888803 12994 solver.cpp:237]     Train net output #0: loss = 0.00234181 (* 1 = 0.00234181 loss)
I0826 17:25:10.890442 12994 sgd_solver.cpp:105] Iteration 9600, lr = 0.00603682
I0826 17:25:45.079592 12994 solver.cpp:218] Iteration 9700 (2.92483 iter/s, 34.19s/100 iters), loss = 0.00109469
I0826 17:25:45.081516 12994 solver.cpp:237]     Train net output #0: loss = 0.00109464 (* 1 = 0.00109464 loss)
I0826 17:25:45.083782 12994 sgd_solver.cpp:105] Iteration 9700, lr = 0.00601382
I0826 17:26:17.088578 12994 solver.cpp:218] Iteration 9800 (3.12432 iter/s, 32.007s/100 iters), loss = 0.00640478
I0826 17:26:17.091372 12994 solver.cpp:237]     Train net output #0: loss = 0.00640473 (* 1 = 0.00640473 loss)
I0826 17:26:17.092232 12994 sgd_solver.cpp:105] Iteration 9800, lr = 0.00599102
I0826 17:26:48.987501 12994 solver.cpp:218] Iteration 9900 (3.13519 iter/s, 31.896s/100 iters), loss = 0.00364594
I0826 17:26:48.992383 12994 solver.cpp:237]     Train net output #0: loss = 0.00364589 (* 1 = 0.00364589 loss)
I0826 17:26:48.992429 12994 sgd_solver.cpp:105] Iteration 9900, lr = 0.00596843
I0826 17:27:23.194376 12994 solver.cpp:447] Snapshotting to binary proto file examples/mnist/snapshot_iter_10000.caffemodel
I0826 17:27:23.236954 12994 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snapshot_iter_10000.solverstate
I0826 17:27:23.351760 12994 solver.cpp:310] Iteration 10000, loss = 0.00171137
I0826 17:27:23.352002 12994 solver.cpp:330] Iteration 10000, Testing net (#0)
I0826 17:27:42.615217 12997 data_layer.cpp:73] Restarting data prefetching from start.
I0826 17:27:43.606931 12994 solver.cpp:397]     Test net output #0: accuracy = 0.9923
I0826 17:27:43.607431 12994 solver.cpp:397]     Test net output #1: loss = 0.0254701 (* 1 = 0.0254701 loss)
I0826 17:27:43.608405 12994 solver.cpp:315] Optimization Done.
I0826 17:27:43.635915 12994 caffe.cpp:259] Optimization Done.
