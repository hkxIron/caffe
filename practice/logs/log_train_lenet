/home/hkx/caffe_hkx/build/tools/caffe: /home/hkx/anaconda2/lib/libtiff.so.5: no version information available (required by /usr/lib/x86_64-linux-gnu/libopencv_highgui.so.2.4)
I1030 21:07:11.473134 14357 caffe.cpp:211] Use CPU.
I1030 21:07:11.476511 14357 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
net: "examples/mnist/lenet_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I1030 21:07:11.483914 14357 solver.cpp:90] Creating training net from net file: examples/mnist/lenet_train_test.prototxt
I1030 21:07:11.484513 14357 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I1030 21:07:11.484851 14357 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1030 21:07:11.484935 14357 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1030 21:07:11.485244 14357 layer_factory.hpp:77] Creating layer mnist
I1030 21:07:11.485754 14357 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I1030 21:07:11.485792 14357 net.cpp:84] Creating Layer mnist
I1030 21:07:11.485810 14357 net.cpp:380] mnist -> data
I1030 21:07:11.485837 14357 net.cpp:380] mnist -> label
I1030 21:07:11.485879 14357 data_layer.cpp:45] output data size: 64,1,28,28
I1030 21:07:11.486346 14357 net.cpp:122] Setting up mnist
I1030 21:07:11.487022 14357 net.cpp:129] Top shape: 64 1 28 28 (50176)
I1030 21:07:11.487038 14357 net.cpp:129] Top shape: 64 (64)
I1030 21:07:11.487049 14357 net.cpp:137] Memory required for data: 200960
I1030 21:07:11.487064 14357 layer_factory.hpp:77] Creating layer conv1
I1030 21:07:11.487087 14357 net.cpp:84] Creating Layer conv1
I1030 21:07:11.487102 14357 net.cpp:406] conv1 <- data
I1030 21:07:11.487121 14357 net.cpp:380] conv1 -> conv1
I1030 21:07:11.487169 14357 net.cpp:122] Setting up conv1
I1030 21:07:11.487185 14357 net.cpp:129] Top shape: 64 20 24 24 (737280)
I1030 21:07:11.487195 14357 net.cpp:137] Memory required for data: 3150080
I1030 21:07:11.487232 14357 layer_factory.hpp:77] Creating layer pool1
I1030 21:07:11.487663 14357 net.cpp:84] Creating Layer pool1
I1030 21:07:11.487677 14357 net.cpp:406] pool1 <- conv1
I1030 21:07:11.488267 14357 net.cpp:380] pool1 -> pool1
I1030 21:07:11.488307 14357 net.cpp:122] Setting up pool1
I1030 21:07:11.488322 14357 net.cpp:129] Top shape: 64 20 12 12 (184320)
I1030 21:07:11.488333 14357 net.cpp:137] Memory required for data: 3887360
I1030 21:07:11.488344 14357 layer_factory.hpp:77] Creating layer conv2
I1030 21:07:11.488360 14357 net.cpp:84] Creating Layer conv2
I1030 21:07:11.488373 14357 net.cpp:406] conv2 <- pool1
I1030 21:07:11.488385 14357 net.cpp:380] conv2 -> conv2
I1030 21:07:11.488591 14357 net.cpp:122] Setting up conv2
I1030 21:07:11.489161 14357 net.cpp:129] Top shape: 64 50 8 8 (204800)
I1030 21:07:11.489178 14357 net.cpp:137] Memory required for data: 4706560
I1030 21:07:11.489804 14357 layer_factory.hpp:77] Creating layer pool2
I1030 21:07:11.489840 14357 net.cpp:84] Creating Layer pool2
I1030 21:07:11.489853 14357 net.cpp:406] pool2 <- conv2
I1030 21:07:11.489868 14357 net.cpp:380] pool2 -> pool2
I1030 21:07:11.489890 14357 net.cpp:122] Setting up pool2
I1030 21:07:11.490767 14357 net.cpp:129] Top shape: 64 50 4 4 (51200)
I1030 21:07:11.490782 14357 net.cpp:137] Memory required for data: 4911360
I1030 21:07:11.490792 14357 layer_factory.hpp:77] Creating layer ip1
I1030 21:07:11.490808 14357 net.cpp:84] Creating Layer ip1
I1030 21:07:11.490819 14357 net.cpp:406] ip1 <- pool2
I1030 21:07:11.490833 14357 net.cpp:380] ip1 -> ip1
I1030 21:07:11.505100 14357 net.cpp:122] Setting up ip1
I1030 21:07:11.505632 14357 net.cpp:129] Top shape: 64 500 (32000)
I1030 21:07:11.506084 14357 net.cpp:137] Memory required for data: 5039360
I1030 21:07:11.506567 14357 layer_factory.hpp:77] Creating layer relu1
I1030 21:07:11.507027 14357 net.cpp:84] Creating Layer relu1
I1030 21:07:11.507459 14357 net.cpp:406] relu1 <- ip1
I1030 21:07:11.507930 14357 net.cpp:367] relu1 -> ip1 (in-place)
I1030 21:07:11.508369 14357 net.cpp:122] Setting up relu1
I1030 21:07:11.508796 14357 net.cpp:129] Top shape: 64 500 (32000)
I1030 21:07:11.508908 14357 net.cpp:137] Memory required for data: 5167360
I1030 21:07:11.508924 14357 layer_factory.hpp:77] Creating layer ip2
I1030 21:07:11.508939 14357 net.cpp:84] Creating Layer ip2
I1030 21:07:11.508950 14357 net.cpp:406] ip2 <- ip1
I1030 21:07:11.509358 14357 net.cpp:380] ip2 -> ip2
I1030 21:07:11.509428 14357 net.cpp:122] Setting up ip2
I1030 21:07:11.509449 14357 net.cpp:129] Top shape: 64 10 (640)
I1030 21:07:11.509460 14357 net.cpp:137] Memory required for data: 5169920
I1030 21:07:11.509475 14357 layer_factory.hpp:77] Creating layer loss
I1030 21:07:11.509491 14357 net.cpp:84] Creating Layer loss
I1030 21:07:11.509502 14357 net.cpp:406] loss <- ip2
I1030 21:07:11.509515 14357 net.cpp:406] loss <- label
I1030 21:07:11.509528 14357 net.cpp:380] loss -> loss
I1030 21:07:11.509552 14357 layer_factory.hpp:77] Creating layer loss
I1030 21:07:11.509574 14357 net.cpp:122] Setting up loss
I1030 21:07:11.509588 14357 net.cpp:129] Top shape: (1)
I1030 21:07:11.509598 14357 net.cpp:132]     with loss weight 1
I1030 21:07:11.509621 14357 net.cpp:137] Memory required for data: 5169924
I1030 21:07:11.509632 14357 net.cpp:198] loss needs backward computation.
I1030 21:07:11.509647 14357 net.cpp:198] ip2 needs backward computation.
I1030 21:07:11.509658 14357 net.cpp:198] relu1 needs backward computation.
I1030 21:07:11.509668 14357 net.cpp:198] ip1 needs backward computation.
I1030 21:07:11.509680 14357 net.cpp:198] pool2 needs backward computation.
I1030 21:07:11.509690 14357 net.cpp:198] conv2 needs backward computation.
I1030 21:07:11.509701 14357 net.cpp:198] pool1 needs backward computation.
I1030 21:07:11.509712 14357 net.cpp:198] conv1 needs backward computation.
I1030 21:07:11.509723 14357 net.cpp:200] mnist does not need backward computation.
I1030 21:07:11.509733 14357 net.cpp:242] This network produces output loss
I1030 21:07:11.509750 14357 net.cpp:255] Network initialization done.
I1030 21:07:11.510466 14357 solver.cpp:175] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I1030 21:07:11.510500 14357 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I1030 21:07:11.510588 14357 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1030 21:07:11.511517 14357 layer_factory.hpp:77] Creating layer mnist
I1030 21:07:11.511579 14357 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I1030 21:07:11.512181 14357 net.cpp:84] Creating Layer mnist
I1030 21:07:11.512202 14357 net.cpp:380] mnist -> data
I1030 21:07:11.512219 14357 net.cpp:380] mnist -> label
I1030 21:07:11.512244 14357 data_layer.cpp:45] output data size: 100,1,28,28
I1030 21:07:11.512329 14357 net.cpp:122] Setting up mnist
I1030 21:07:11.512351 14357 net.cpp:129] Top shape: 100 1 28 28 (78400)
I1030 21:07:11.512363 14357 net.cpp:129] Top shape: 100 (100)
I1030 21:07:11.512373 14357 net.cpp:137] Memory required for data: 314000
I1030 21:07:11.512385 14357 layer_factory.hpp:77] Creating layer label_mnist_1_split
I1030 21:07:11.512399 14357 net.cpp:84] Creating Layer label_mnist_1_split
I1030 21:07:11.512411 14357 net.cpp:406] label_mnist_1_split <- label
I1030 21:07:11.512425 14357 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0
I1030 21:07:11.512441 14357 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1
I1030 21:07:11.512457 14357 net.cpp:122] Setting up label_mnist_1_split
I1030 21:07:11.512470 14357 net.cpp:129] Top shape: 100 (100)
I1030 21:07:11.512481 14357 net.cpp:129] Top shape: 100 (100)
I1030 21:07:11.512491 14357 net.cpp:137] Memory required for data: 314800
I1030 21:07:11.512501 14357 layer_factory.hpp:77] Creating layer conv1
I1030 21:07:11.512519 14357 net.cpp:84] Creating Layer conv1
I1030 21:07:11.512532 14357 net.cpp:406] conv1 <- data
I1030 21:07:11.512593 14357 net.cpp:380] conv1 -> conv1
I1030 21:07:11.512713 14357 net.cpp:122] Setting up conv1
I1030 21:07:11.512984 14357 net.cpp:129] Top shape: 100 20 24 24 (1152000)
I1030 21:07:11.513074 14357 net.cpp:137] Memory required for data: 4922800
I1030 21:07:11.513232 14357 layer_factory.hpp:77] Creating layer pool1
I1030 21:07:11.517024 14357 net.cpp:84] Creating Layer pool1
I1030 21:07:11.517869 14357 net.cpp:406] pool1 <- conv1
I1030 21:07:11.518091 14357 net.cpp:380] pool1 -> pool1
I1030 21:07:11.520902 14357 net.cpp:122] Setting up pool1
I1030 21:07:11.521189 14357 net.cpp:129] Top shape: 100 20 12 12 (288000)
I1030 21:07:11.521210 14357 net.cpp:137] Memory required for data: 6074800
I1030 21:07:11.521229 14357 layer_factory.hpp:77] Creating layer conv2
I1030 21:07:11.521258 14357 net.cpp:84] Creating Layer conv2
I1030 21:07:11.521373 14357 net.cpp:406] conv2 <- pool1
I1030 21:07:11.521404 14357 net.cpp:380] conv2 -> conv2
I1030 21:07:11.521847 14357 net.cpp:122] Setting up conv2
I1030 21:07:11.522897 14357 net.cpp:129] Top shape: 100 50 8 8 (320000)
I1030 21:07:11.522925 14357 net.cpp:137] Memory required for data: 7354800
I1030 21:07:11.523063 14357 layer_factory.hpp:77] Creating layer pool2
I1030 21:07:11.523092 14357 net.cpp:84] Creating Layer pool2
I1030 21:07:11.523181 14357 net.cpp:406] pool2 <- conv2
I1030 21:07:11.523205 14357 net.cpp:380] pool2 -> pool2
I1030 21:07:11.523329 14357 net.cpp:122] Setting up pool2
I1030 21:07:11.523353 14357 net.cpp:129] Top shape: 100 50 4 4 (80000)
I1030 21:07:11.524152 14357 net.cpp:137] Memory required for data: 7674800
I1030 21:07:11.524287 14357 layer_factory.hpp:77] Creating layer ip1
I1030 21:07:11.524312 14357 net.cpp:84] Creating Layer ip1
I1030 21:07:11.524324 14357 net.cpp:406] ip1 <- pool2
I1030 21:07:11.524339 14357 net.cpp:380] ip1 -> ip1
I1030 21:07:11.542794 14357 net.cpp:122] Setting up ip1
I1030 21:07:11.543347 14357 net.cpp:129] Top shape: 100 500 (50000)
I1030 21:07:11.543896 14357 net.cpp:137] Memory required for data: 7874800
I1030 21:07:11.544450 14357 layer_factory.hpp:77] Creating layer relu1
I1030 21:07:11.544891 14357 net.cpp:84] Creating Layer relu1
I1030 21:07:11.545359 14357 net.cpp:406] relu1 <- ip1
I1030 21:07:11.545791 14357 net.cpp:367] relu1 -> ip1 (in-place)
I1030 21:07:11.546252 14357 net.cpp:122] Setting up relu1
I1030 21:07:11.546663 14357 net.cpp:129] Top shape: 100 500 (50000)
I1030 21:07:11.546675 14357 net.cpp:137] Memory required for data: 8074800
I1030 21:07:11.546686 14357 layer_factory.hpp:77] Creating layer ip2
I1030 21:07:11.546705 14357 net.cpp:84] Creating Layer ip2
I1030 21:07:11.546720 14357 net.cpp:406] ip2 <- ip1
I1030 21:07:11.546735 14357 net.cpp:380] ip2 -> ip2
I1030 21:07:11.546797 14357 net.cpp:122] Setting up ip2
I1030 21:07:11.547292 14357 net.cpp:129] Top shape: 100 10 (1000)
I1030 21:07:11.547305 14357 net.cpp:137] Memory required for data: 8078800
I1030 21:07:11.547323 14357 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I1030 21:07:11.547340 14357 net.cpp:84] Creating Layer ip2_ip2_0_split
I1030 21:07:11.547353 14357 net.cpp:406] ip2_ip2_0_split <- ip2
I1030 21:07:11.547365 14357 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_0
I1030 21:07:11.547380 14357 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_1
I1030 21:07:11.547396 14357 net.cpp:122] Setting up ip2_ip2_0_split
I1030 21:07:11.547410 14357 net.cpp:129] Top shape: 100 10 (1000)
I1030 21:07:11.547420 14357 net.cpp:129] Top shape: 100 10 (1000)
I1030 21:07:11.547430 14357 net.cpp:137] Memory required for data: 8086800
I1030 21:07:11.547441 14357 layer_factory.hpp:77] Creating layer accuracy
I1030 21:07:11.547454 14357 net.cpp:84] Creating Layer accuracy
I1030 21:07:11.547466 14357 net.cpp:406] accuracy <- ip2_ip2_0_split_0
I1030 21:07:11.547477 14357 net.cpp:406] accuracy <- label_mnist_1_split_0
I1030 21:07:11.547492 14357 net.cpp:380] accuracy -> accuracy
I1030 21:07:11.547508 14357 net.cpp:122] Setting up accuracy
I1030 21:07:11.547520 14357 net.cpp:129] Top shape: (1)
I1030 21:07:11.547530 14357 net.cpp:137] Memory required for data: 8086804
I1030 21:07:11.547541 14357 layer_factory.hpp:77] Creating layer loss
I1030 21:07:11.547554 14357 net.cpp:84] Creating Layer loss
I1030 21:07:11.547565 14357 net.cpp:406] loss <- ip2_ip2_0_split_1
I1030 21:07:11.547583 14357 net.cpp:406] loss <- label_mnist_1_split_1
I1030 21:07:11.547621 14357 net.cpp:380] loss -> loss
I1030 21:07:11.547643 14357 layer_factory.hpp:77] Creating layer loss
I1030 21:07:11.547673 14357 net.cpp:122] Setting up loss
I1030 21:07:11.547686 14357 net.cpp:129] Top shape: (1)
I1030 21:07:11.547698 14357 net.cpp:132]     with loss weight 1
I1030 21:07:11.547713 14357 net.cpp:137] Memory required for data: 8086808
I1030 21:07:11.547724 14357 net.cpp:198] loss needs backward computation.
I1030 21:07:11.548271 14357 net.cpp:200] accuracy does not need backward computation.
I1030 21:07:11.548287 14357 net.cpp:198] ip2_ip2_0_split needs backward computation.
I1030 21:07:11.548300 14357 net.cpp:198] ip2 needs backward computation.
I1030 21:07:11.548310 14357 net.cpp:198] relu1 needs backward computation.
I1030 21:07:11.548321 14357 net.cpp:198] ip1 needs backward computation.
I1030 21:07:11.548331 14357 net.cpp:198] pool2 needs backward computation.
I1030 21:07:11.548342 14357 net.cpp:198] conv2 needs backward computation.
I1030 21:07:11.548353 14357 net.cpp:198] pool1 needs backward computation.
I1030 21:07:11.548364 14357 net.cpp:198] conv1 needs backward computation.
I1030 21:07:11.548375 14357 net.cpp:200] label_mnist_1_split does not need backward computation.
I1030 21:07:11.548388 14357 net.cpp:200] mnist does not need backward computation.
I1030 21:07:11.548398 14357 net.cpp:242] This network produces output accuracy
I1030 21:07:11.548408 14357 net.cpp:242] This network produces output loss
I1030 21:07:11.548427 14357 net.cpp:255] Network initialization done.
I1030 21:07:11.548475 14357 solver.cpp:57] Solver scaffolding done.
I1030 21:07:11.548506 14357 caffe.cpp:248] Starting Optimization
I1030 21:07:11.548518 14357 solver.cpp:273] Solving LeNet
I1030 21:07:11.548528 14357 solver.cpp:274] Learning Rate Policy: inv
I1030 21:07:11.548948 14357 solver.cpp:331] Iteration 0, Testing net (#0)
I1030 21:07:23.705482 14360 data_layer.cpp:73] Restarting data prefetching from start.
I1030 21:07:24.235301 14357 solver.cpp:398]     Test net output #0: accuracy = 0.1222
I1030 21:07:24.236251 14357 solver.cpp:398]     Test net output #1: loss = 2.37167 (* 1 = 2.37167 loss)
I1030 21:07:24.471496 14357 solver.cpp:220] Iteration 0 (0 iter/s, 12.922s/100 iters), loss = 2.35369
I1030 21:07:24.472405 14357 solver.cpp:239]     Train net output #0: loss = 2.35369 (* 1 = 2.35369 loss)
I1030 21:07:24.473131 14357 sgd_solver.cpp:105] Iteration 0, lr = 0.01
